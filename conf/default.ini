[global]
# 通用配置
environment = "${ENVIRONMENT}" # 識別當前 Git 分支，並載入對應的 `.env`
log_level = info

[server]
protocol = https
port = 8080
cert_file = /etc/grafana/keys/certificate.pem
cert_key = /etc/grafana/keys/private.pem
# 服務器通用配置
retry_max_attempts = 3
retry_initial_interval = 1
retry_max_interval = 5


[database]
type = "mysql"
host = "127.0.0.1:3306"
name = "grafana"
user = "root"
password = "${DB_PASSWORD}"

[auth]
url = "https://localhost:3000"
client_id = ipoc-oauth
client_secret = "${AUTH_CLIENT_SECRET}"

# 日誌設定
[logging]
level = "${LOG_LEVEL}"
path = "${APP_DIR}/logs/analytics-service.log"

#################################### LLM Service ####################################
[llm_service]
mode = api
timeout = 30
max_tokens = 1000
temperature = 0.7

[llm_service.api]
provider = openai
url = https://api.openai.com/v1
model = gpt-3.5-turbo
api_key = sk-xxx
organization = 

[llm_service.local]
host = http://localhost:8001
model_path = ./models/llama2
device = cuda
top_p = 0.9
top_k = 40
repeat_penalty = 1.1

#################################### Anomaly Service ####################################
[anomaly_service]
host = 0.0.0.0
port = 5001
workers = 4
timeout = 30

[anomaly_service.detectors.absolute_threshold]
window_size = 60

[anomaly_service.detectors.moving_average]
window_size = 60
std_dev = 2.0
moving_average_threshold = 0.2

[anomaly_service.detectors.isolation_forest]
contamination = 0.1
n_estimators = 100
max_samples = auto
random_state = 42
max_features = 1.0

[anomaly_service.detectors.percentage_threshold]
critical = 90.0
warning = 80.0

[anomaly_service.detectors.prophet]
seasonality_mode = multiplicative
changepoint_prior_scale = 0.05
interval_width = 0.95
uncertainty_samples = 1000
horizon = 86400s
period = 60s
holidays_prior_scale = 10.0
weekly_seasonality = true
daily_seasonality = true
yearly_seasonality = false

[anomaly_service.monitoring]
enabled = true
metrics_port = 9090 